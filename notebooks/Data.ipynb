{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cb2d658",
   "metadata": {},
   "source": [
    "## (Model Name): Real-Time Single Channel Speaker Counting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24da4971",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import math\n",
    "import soundfile as sf\n",
    "import re\n",
    "from pathlib import Path\n",
    "import librosa\n",
    "\n",
    "from src.utils.SpectrogramExtractor import SpectrogramExtractor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1027f4fd",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f3f8a1",
   "metadata": {},
   "source": [
    "1. Collect paths for recordings and metadata\n",
    "2. Transform raw_recordings into 1 second mono clips.\n",
    "3. Create the spectrograms for each 1 second clip. \n",
    "4. Use metadata to create the labels for each clip - how many speakers there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67ecb99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 - collect paths\n",
    "\n",
    "# Collect list of paths in libricss dataset. Returns the raw recording wav path & the meeting_info txt path.\n",
    "# For each session there is (raw_recording.wav, meeting_info.txt)\n",
    "def collect_paths(root_dir):\n",
    "    pairs = []\n",
    "\n",
    "    for overlap_dir in Path(root_dir).iterdir():\n",
    "        if not overlap_dir.is_dir():\n",
    "            continue\n",
    "\n",
    "        for session_dir in overlap_dir.iterdir():\n",
    "            raw_path = session_dir / \"record\" / \"raw_recording.wav\"\n",
    "            info_path = session_dir / \"transcription\" / \"meeting_info.txt\"\n",
    "            if raw_path.exists() and info_path.exists():\n",
    "                pairs.append((raw_path, info_path))\n",
    "\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0801569f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 - split recordings into 1s mono clips\n",
    "\n",
    "\n",
    "# Split a wav into chunks of length clip_dur. If clip_dur isn't a factor of the audio's length, the end is discarded.\n",
    "# Necessary so spectrogram images are always same size. CNNs struggle with varying size inputs.\n",
    "\n",
    "def split_wav_into_clips(wav_path, clip_dur=1.0, sr=16000):\n",
    "    wav, _ = librosa.load(wav_path, sr=sr, mono=True) # librosa handles mono conversion for us\n",
    "    clip_len = int(clip_dur * sr)\n",
    "    num_clips = len(wav) // clip_len\n",
    "\n",
    "    clips = [\n",
    "        wav[i * clip_len : (i + 1) * clip_len]\n",
    "        for i in range(num_clips)\n",
    "    ]\n",
    "    return clips\n",
    "\n",
    "\n",
    "def wavs_to_clips():\n",
    "    # Destination dir\n",
    "    out_dir = Path(\"data/clips\")\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "    for raw_path, _ in collect_paths(\"data/libricss\"):\n",
    "\n",
    "        # Formatting for file names\n",
    "        speaker = raw_path.parents[2].name\n",
    "        session_folder = raw_path.parents[1].name\n",
    "        m = re.search(r\"(session\\d+)\", session_folder)\n",
    "        session = m.group(1) if m else session_folder\n",
    "\n",
    "        # Split raw_path into 1s clips\n",
    "        clips = split_wav_into_clips(raw_path, clip_dur=1.0, sr=16000)\n",
    "\n",
    "        # Save clips \n",
    "        for idx, clip in enumerate(clips):\n",
    "            fname = f\"{speaker}_{session}_clip{idx}.wav\"\n",
    "            sf.write(out_dir / fname, clip, 16000)\n",
    "\n",
    "# wavs_to_clips()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a12a9373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 - turn each clip into spectrogram\n",
    "def clips_to_specs():\n",
    "    extractor = SpectrogramExtractor()\n",
    "\n",
    "\n",
    "    clips_dir = Path(\"data/clips\")\n",
    "    specs_dir = Path(\"data/spectrograms\")\n",
    "    specs_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Convert all clips to spectrograms\n",
    "    for wav_path in clips_dir.glob(\"*.wav\"):\n",
    "\n",
    "        spec = extractor(str(wav_path))   # Returns a tensor shape: [1, n_mels, time_frames]\n",
    "        spec = spec.squeeze(0)  # Remove the leading channel dim. Now [n_mels, time_frames]\n",
    "        \n",
    "\n",
    "        out_path = specs_dir / wav_path.with_suffix(\".pt\").name\n",
    "        torch.save(spec, out_path) # save as a PyTorch tensor\n",
    "\n",
    "# clips_to_specs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cec7c883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "spectrogram",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "speaker_count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "490759ca-207a-4e81-a350-8df903054482",
       "rows": [
        [
         "0",
         "0L_session0_clip0.pt",
         "0"
        ],
        [
         "1",
         "0L_session0_clip1.pt",
         "0"
        ],
        [
         "2",
         "0L_session0_clip10.pt",
         "1"
        ],
        [
         "3",
         "0L_session0_clip100.pt",
         "1"
        ],
        [
         "4",
         "0L_session0_clip101.pt",
         "1"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spectrogram</th>\n",
       "      <th>speaker_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0L_session0_clip0.pt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0L_session0_clip1.pt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0L_session0_clip10.pt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0L_session0_clip100.pt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0L_session0_clip101.pt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              spectrogram  speaker_count\n",
       "0    0L_session0_clip0.pt              0\n",
       "1    0L_session0_clip1.pt              0\n",
       "2   0L_session0_clip10.pt              1\n",
       "3  0L_session0_clip100.pt              1\n",
       "4  0L_session0_clip101.pt              1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4 - labels for each spectrogram\n",
    "\n",
    "\n",
    "# 1) Create a wrapper to find the number of speakers in each defined time window\n",
    "def count_speakers_per_window(meeting_file, time_window=1.0):\n",
    "\n",
    "\n",
    "    # Parse the start and end time from meeting_file\n",
    "    intervals = []\n",
    "    with open(meeting_file, \"r\") as f:\n",
    "        next(f)  # Skip header line\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            start_time = float(parts[0])\n",
    "            end_time = float(parts[1])\n",
    "            intervals.append((start_time, end_time))\n",
    "    if not intervals:\n",
    "        return []\n",
    "\n",
    "\n",
    "\n",
    "    # Count the number of speakers active for each time_window\n",
    "    max_time = max(end for _, end in intervals)\n",
    "    num_windows = math.ceil(max_time / time_window)\n",
    "    speaker_counts = [0] * num_windows\n",
    "\n",
    "    for start, end in intervals:\n",
    "        start_idx = int(start // time_window)\n",
    "        end_idx = int(end // time_window)\n",
    "\n",
    "        for i in range(start_idx, end_idx + 1):\n",
    "            if i < num_windows:\n",
    "                speaker_counts[i] += 1\n",
    "\n",
    "    return speaker_counts\n",
    "\n",
    "\n",
    "\n",
    "# 2) Build a dict {spectrogram path -> its label, from 1)}\n",
    "\n",
    "\n",
    "# Collect Key paths\n",
    "specs_dir = Path(\"data/spectrograms\")\n",
    "spec_to_label = {}\n",
    "\n",
    "\n",
    "\n",
    "# Collect value paths\n",
    "counts_map = {}\n",
    "for _, info_path in collect_paths(\"data/libricss\"):\n",
    "    speaker = info_path.parents[2].name \n",
    "    session_folder = info_path.parents[1].name\n",
    "    \n",
    "\n",
    "    m = re.search(r\"(session\\d+)\", session_folder)\n",
    "    session = m.group(1) if m else session_folder\n",
    "    \n",
    "    key = f\"{speaker}_{session}\"              \n",
    "    counts_map[key] = count_speakers_per_window(info_path)\n",
    "\n",
    "\n",
    "\n",
    "# Create key/value pair\n",
    "for spec_path in specs_dir.glob(\"*.pt\"):\n",
    "    stem = spec_path.stem \n",
    "    parts = stem.rsplit(\"_clip\", 1)    \n",
    "    if len(parts) != 2:\n",
    "        continue  \n",
    "    \n",
    "    key, idx_str = parts\n",
    "    idx = int(idx_str)\n",
    "    \n",
    "    if key not in counts_map:\n",
    "        raise KeyError(f\"No counts for session key '{key}'\")\n",
    "    counts = counts_map[key]\n",
    "    \n",
    "    if idx < 0 or idx >= len(counts):\n",
    "        raise IndexError(f\"Clip index {idx} out of range for '{key}'\")\n",
    "    \n",
    "    spec_to_label[spec_path] = counts[idx]\n",
    "\n",
    "\n",
    "\n",
    "# 3) Result\n",
    "records = [\n",
    "    {\"spectrogram\": path.name, \"speaker_count\": label}\n",
    "    for path, label in spec_to_label.items()\n",
    "]\n",
    "df = pd.DataFrame(records); df.head()\n",
    "\n",
    "\n",
    "\n",
    "# 4) Save mapping to csv\n",
    "# df.to_csv(\"data/spectrogram_labels.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd9d8d5",
   "metadata": {},
   "source": [
    "## Final DataFrame: Labelled Spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "468a3446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "spectrogram",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "speaker_count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "cc83de5f-0148-4d8b-b6ad-894812a0d3bd",
       "rows": [
        [
         "0",
         "0L_session0_clip0.pt",
         "0"
        ],
        [
         "1",
         "0L_session0_clip1.pt",
         "0"
        ],
        [
         "2",
         "0L_session0_clip10.pt",
         "1"
        ],
        [
         "3",
         "0L_session0_clip100.pt",
         "1"
        ],
        [
         "4",
         "0L_session0_clip101.pt",
         "1"
        ],
        [
         "5",
         "0L_session0_clip102.pt",
         "1"
        ],
        [
         "6",
         "0L_session0_clip103.pt",
         "1"
        ],
        [
         "7",
         "0L_session0_clip104.pt",
         "1"
        ],
        [
         "8",
         "0L_session0_clip105.pt",
         "1"
        ],
        [
         "9",
         "0L_session0_clip106.pt",
         "1"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spectrogram</th>\n",
       "      <th>speaker_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0L_session0_clip0.pt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0L_session0_clip1.pt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0L_session0_clip10.pt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0L_session0_clip100.pt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0L_session0_clip101.pt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0L_session0_clip102.pt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0L_session0_clip103.pt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0L_session0_clip104.pt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0L_session0_clip105.pt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0L_session0_clip106.pt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              spectrogram  speaker_count\n",
       "0    0L_session0_clip0.pt              0\n",
       "1    0L_session0_clip1.pt              0\n",
       "2   0L_session0_clip10.pt              1\n",
       "3  0L_session0_clip100.pt              1\n",
       "4  0L_session0_clip101.pt              1\n",
       "5  0L_session0_clip102.pt              1\n",
       "6  0L_session0_clip103.pt              1\n",
       "7  0L_session0_clip104.pt              1\n",
       "8  0L_session0_clip105.pt              1\n",
       "9  0L_session0_clip106.pt              1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
