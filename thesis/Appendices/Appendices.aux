\relax 
\citation{libricss}
\citation{libricss}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}LibriCSS Metadata}{19}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{app:libricss_metadata}{{A}{19}{}{chapter.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {A.1}{\ignorespaces A metadata sample from LibriCSS \cite  {libricss}. By scraping the start and end time of each utterance it's possible to know how many speakers are present in each clip. For example it's clear that at $t=8$ there are two speakers, because the first and second speakers are speaking in overlap.}}{19}{}\protected@file@percent }
\newlabel{tab:libricss_metadata}{{A.1}{19}{}{table.1.1}{}}
\citation{modelsizes}
\citation{modelsizes}
\@writefile{toc}{\contentsline {chapter}{\numberline {B}Model Architectures}{20}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {B.1}Voice Activity Detection (VAD) Architecture}{20}{}\protected@file@percent }
\newlabel{app:VAD_arc}{{B.1}{20}{}{section.2.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {B.1}{\ignorespaces Summary of the Voice Activity Detection model. Most of the computation is done in the fully-connected (linear) layers, as the VAD task doesn't require much hierarchical learning.}}{20}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {B.2}Speaker Counter Architecture}{21}{}\protected@file@percent }
\newlabel{app:SC_arc}{{B.2}{21}{}{section.2.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {B.2}{\ignorespaces Summary of the Speaker Counting CNN. At 0.6M parameters the model is very compact relative to modern deep networks \cite  {modelsizes}. Despite being more architecturally complex, this model is smaller than the VAD model; the four convolutional layers provide a much higher compression rate. Most of the computation is done in the convolutional layers to maximise the extraction of hierarchical features. \newline  \newline  \textbf  {*}The main model contains 5 classes, [0,1,2,3,4+]; an additional `post-VAD' model was made with 4 classes, [1,2,3,4+]. The post-VAD model assumes speech in the audio. The post-VAD model wasn't significantly different to this model.}}{21}{}\protected@file@percent }
\@setckpt{Appendices/Appendices}{
\setcounter{page}{22}
\setcounter{equation}{0}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{7}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{2}
\setcounter{section}{2}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{0}
\setcounter{table}{2}
\setcounter{parentequation}{0}
\setcounter{float@type}{32}
\setcounter{algorithm}{0}
\setcounter{ALC@unique}{0}
\setcounter{ALC@line}{0}
\setcounter{ALC@rem}{0}
\setcounter{ALC@depth}{0}
\setcounter{subfigure}{0}
\setcounter{lofdepth}{1}
\setcounter{subtable}{0}
\setcounter{lotdepth}{1}
\setcounter{FancyVerbLine}{0}
\setcounter{linenumber}{1}
\setcounter{LN@truepage}{21}
\setcounter{FancyVerbWriteLine}{0}
\setcounter{FancyVerbBufferLine}{0}
\setcounter{FV@TrueTabGroupLevel}{0}
\setcounter{FV@TrueTabCounter}{0}
\setcounter{FV@HighlightLinesStart}{0}
\setcounter{FV@HighlightLinesStop}{0}
\setcounter{FancyVerbLineBreakLast}{0}
\setcounter{FV@BreakBufferDepth}{0}
\setcounter{minted@FancyVerbLineTemp}{0}
\setcounter{listing}{0}
\setcounter{lstnumber}{1}
\setcounter{lstlisting}{0}
}
