\chapter{Spectrogram Example}
\label{app:bat_spec}
\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{figs/Intro&Review/bat.png}
\caption{A spectrogram of a bat's echolocation \cite{bat_echolocation_jones}. Spectrograms encode temporal and frequency information simultaneously, making them well-suited for CNN-based feature extraction.}
\end{figure}


\chapter{LibriCSS Metadata}
\label{app:libricss_metadata}

\begin{table}[H]
  \centering
  \caption{A metadata sample from LibriCSS \cite{libricss}. By scraping the start and end time of each utterance it's possible to know how many speakers are present in each clip. For example it's clear that at $t=8$ there are two speakers, because the first and second speakers are speaking in overlap.}
  \label{tab:libricss_metadata}
  \begin{tabular}{|c|c|c|c|p{8cm}|}
    \hline
    \textbf{Start Time} & \textbf{End Time} & \textbf{Speaker} & \textbf{Utterance ID} & \textbf{Transcription} \\
    \hline
    3.000 & 10.260 & 3570 & 3570-5695-0002 & BUT AS WE DESCEND THE SOCIAL SCALE THE POINT IS PRESENTLY REACHED WHERE THE DUTIES OF VICARIOUS LEISURE AND CONSUMPTION DEVOLVE UPON THE WIFE ALONE \\
    \hline
    6.416 & 14.676 & 3575 & 3575-170457-0013 & THE MORE SHE IS ENGAGED IN HER PROPER DUTIES THE LESS LEISURE WILL SHE HAVE FOR IT EVEN AS AN ACCOMPLISHMENT AND A RECREATION \\
    \hline
    15.650 & 28.690 & 1188 & 1188-133604-0021 & IT WILL BE WHOLLY IMPOSSIBLE FOR YOU TO RETAIN THE TRANQUILLITY OF TEMPER AND FELICITY OF FAITH NECESSARY FOR NOBLE PURIST PAINTING UNLESS YOU ARE ACTIVELY ENGAGED IN PROMOTING THE FELICITY AND PEACE OF PRACTICAL LIFE \\
    \hline
    28.797 & 39.387 & 1188 & 1188-133604-0018 & IN ALL EARLY GOTHIC ART INDEED YOU WILL FIND FAILURE OF THIS KIND ESPECIALLY DISTORTION AND RIGIDITY WHICH ARE IN MANY RESPECTS PAINFULLY TO BE COMPARED WITH THE SPLENDID REPOSE OF CLASSIC ART \\
    \hline
    39.389 & 53.669 & 1188 & 1188-133604-0011 & THEY ARE BEYOND ALL OTHER WORKS THAT I KNOW EXISTING DEPENDENT FOR THEIR EFFECT ON LOW SUBDUED TONES THEIR FAVORITE CHOICE IN TIME OF DAY BEING EITHER DAWN OR TWILIGHT AND EVEN THEIR BRIGHTEST SUNSETS PRODUCED CHIEFLY OUT OF GRAY PAPER \\
    \hline
    48.241 & 58.941 & 7021 & 7021-85628-0001 & HE MADE A BOW SO DEEP THAT HIS BACK CAME NEAR BREAKING AND HE WAS DUMBFOUNDED I CAN TELL YOU WHEN HE SAW IT WAS NOBODY BUT ANDERS \\
    \hline
  \end{tabular}
\end{table}

%---------------------------------------------------------------------------------------------------------
\chapter{Model Architectures}

\section{Voice Activity Detection (VAD) Architecture}
\label{app:VAD_arc}
% VAD summary table
\begin{table}[H]
\centering
\begin{tabular}{|r l l r|}
\hline
\textbf{\#} & \textbf{Layer Type} & \textbf{Output Shape} & \textbf{Param \#} \\
\hline
1 & Conv2d       & [-1, 32, 64, 101] & 320 \\
2 & BatchNorm2d  & [-1, 32, 64, 101] & 64 \\
3 & MaxPool2d    & [-1, 32, 32, 50]  & 0 \\
4 & Conv2d       & [-1, 64, 32, 50]  & 18,496 \\
5 & BatchNorm2d  & [-1, 64, 32, 50]  & 128 \\
6 & MaxPool2d    & [-1, 64, 16, 25]  & 0 \\
7 & Dropout      & [-1, 25600]       & 0 \\
8 & Linear       & [-1, 64]          & 1,638,464 \\
9 & Linear       & [-1, 2]           & 130 \\
\hline
\multicolumn{3}{|l|}{\textbf{Total params}}            & 1,657,602 \\
\hline
\multicolumn{3}{|l|}{Input size (MB)}                  & 0.02 \\
\multicolumn{3}{|l|}{Forward/backward pass size (MB)}  & 5.50 \\
\multicolumn{3}{|l|}{Params size (MB)}                 & 6.32 \\
\multicolumn{3}{|l|}{Estimated Total Size (MB)}        & 11.85 \\
\hline
\end{tabular}
\caption{Summary of the Voice Activity Detection model. Most of the computation is done in the fully-connected (linear) layers, as the VAD task doesn't require much hierarchical learning.}
\end{table}


\section{Speaker Counter Architecture}
\label{app:SC_arc}
% Count summary 
\begin{table}[H]
\centering
\begin{tabular}{|r l l r|}
\hline
\textbf{\#} & \textbf{Layer Type} & \textbf{Output Shape} & \textbf{Param \#} \\
\hline
1  & Conv2d       & [-1, 8, 64, 101]   & 80 \\
2  & BatchNorm2d  & [-1, 8, 64, 101]   & 16 \\
3  & MaxPool2d    & [-1, 8, 32, 50]    & 0 \\
4  & Conv2d       & [-1, 32, 32, 50]   & 2,336 \\
5  & BatchNorm2d  & [-1, 32, 32, 50]   & 64 \\
6  & MaxPool2d    & [-1, 32, 16, 25]   & 0 \\
7  & Conv2d       & [-1, 128, 16, 25]  & 36,992 \\
8  & BatchNorm2d  & [-1, 128, 16, 25]  & 256 \\
9  & MaxPool2d    & [-1, 128, 8, 12]   & 0 \\
10 & Conv2d       & [-1, 128, 8, 12]   & 147,584 \\
11 & BatchNorm2d  & [-1, 128, 8, 12]   & 256 \\
12 & MaxPool2d    & [-1, 128, 4, 6]    & 0 \\
13 & Dropout      & [-1, 3072]         & 0 \\
14 & Linear       & [-1, 128]          & 393,344 \\
15 & Linear       & [-1, 5\textbf{*}]            & 645 \\
\hline
\multicolumn{3}{|l|}{\textbf{Total params}}         & 581,573 \\
\hline
\multicolumn{3}{|l|}{Input size (MB)}                 & 0.02 \\
\multicolumn{3}{|l|}{Forward/backward pass size (MB)} & 2.88 \\
\multicolumn{3}{|l|}{Params size (MB)}                & 2.22 \\
\multicolumn{3}{|l|}{Estimated Total Size (MB)}       & 5.12 \\
\hline
\end{tabular}
\caption{Summary of the Speaker Counting CNN. At 0.6M parameters the model is very compact relative to modern deep networks \cite{modelsizes}. Despite being more architecturally complex, this model is smaller than the VAD model; the four convolutional layers provide a much higher compression rate. Most of the computation is done in the convolutional layers to maximise the extraction of hierarchical features.
\noindent \textbf{*}The main model contains 5 classes, [0,1,2,3,4+]; an additional `post-VAD' model was made with 4 classes, [1,2,3,4+]. The post-VAD model assumes speech in the audio. The post-VAD model wasn't significantly different to this model.}
\end{table}

%---------------------------------------------------------------------------------------------------------
\chapter{GitLab Structure}
\begin{figure}[H]
\centering
\begin{verbatim}
cxb1114/
|-- data/
|   |-- data.wav
|   `-- ...
|
|-- notebooks/
|   |-- DataWrangling.ipynb
|   |-- HPTuning.ipynb
|   |-- ModelTraining1_5Class.ipynb
|   |-- ModelTraining2_4Class.ipynb
|   |-- ModelTraining3_VAD.ipynb
|   `-- Visuals.ipynb
|
|-- src/
|   |-- app.py
|   |-- app_VAD.py
|   |-- data.py
|   |-- model.py
|   |-- predict.py
|   |
|   |-- utils/
|   |   |-- helpers.py
|   |   `-- SpectrogramExtractor.py
|   |
|   `-- model/
|       `-- models.pt
|       `-- ...
|
|-- thesis/
|   `-- dissertation.pdf
|
|-- demo.pptx
`-- requirements.txt


\end{verbatim}
\caption{The project repository structure.}
\end{figure}

Some notes on the repository contents: `\textbf{data/}' is empty because it's too large to store in a repository. `\textbf{notebooks/}' contains all results from practical work, while `\textbf{src/}' contains helper functions, model classes, configs and the real-time apps. `\textbf{src/model/}' contains the model weights.\newline

\noindent A full description and set-up can be found in the readme.
