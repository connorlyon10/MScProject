@inproceedings{pyannote2020,
  Title = {{pyannote.audio: neural building blocks for speaker diarization}},
  Author = {{Bredin}, Herv{\'e} and {Yin}, Ruiqing and {Coria}, Juan Manuel and {Gelly}, Gregory and {Korshunov}, Pavel and {Lavechin}, Marvin and {Fustes}, Diego and {Titeux}, Hadrien and {Bouaziz}, Wassim and {Gill}, Marie-Philippe},
  Booktitle = {ICASSP 2020, IEEE International Conference on Acoustics, Speech, and Signal Processing},
  Address = {Barcelona, Spain},
  Month = {May},
  Year = {2020},
}

@online{ibm_realtime,
  author       = {Alice Gomstyn and Alexandra Jonker},
  title        = {What Is Real-Time Data?},
  year         = {2025},
  month        = {July},
  url          = {https://www.ibm.com/think/topics/real-time-data},
  organization = {IBM},
  note         = {Accessed: 2025-08-29}
}

@inproceedings{pyannote2021,
  Title = {{End-to-end speaker segmentation for overlap-aware resegmentation}},
  Author = {{Bredin}, Herv{\'e} and {Laurent}, Antoine},
  Booktitle = {Proc. Interspeech 2021},
  Address = {Brno, Czech Republic},
  Month = {August},
  Year = {2021},
}


@article{speechbrain,
  title={SpeechBrain: A general-purpose speech toolkit},
  author={Ravanelli, Mirco and Parcollet, Titouan and Plantinga, Peter and Rouhe, Aku and Cornell, Samuele and Lugosch, Loren and Subakan, Cem and Dawalatabad, Nauman and Heba, Abdelwahab and Zhong, Jianyuan and others},
  journal={arXiv preprint arXiv:2106.04624},
  year={2021}
}


@article{nemo,
  title={Nemo: a toolkit for building ai applications using neural modules},
  author={Kuchaiev, Oleksii and Li, Jason and Nguyen, Huyen and Hrinchuk, Oleksii and Leary, Ryan and Ginsburg, Boris and Kriman, Samuel and Beliaev, Stanislav and Lavrukhin, Vitaly and Cook, Jack and others},
  journal={arXiv preprint arXiv:1909.09577},
  year={2019}
}


@article{importance_of_vad,
  title={Voice activity detection. fundamentals and speech recognition system robustness},
  author={Ramirez, Javier and G{\'o}rriz, Juan Manuel and Segura, Jos{\'e} Carlos},
  journal={Robust speech recognition and understanding},
  volume={6},
  number={9},
  pages={1--22},
  year={2007},
  publisher={Vienna, Austria}
}


@inproceedings{importance_of_OSD,
  title={Overlapped speech detection for improved speaker diarization in multiparty meetings},
  author={Boakye, Kofi and Trueba-Hornero, Beatriz and Vinyals, Oriol and Friedland, Gerald},
  booktitle={2008 IEEE international conference on acoustics, speech and signal processing},
  pages={4353--4356},
  year={2008},
  organization={IEEE}
}

@article{vad_review,
  title={A comprehensive empirical review of modern voice activity detection approaches for movies and TV shows},
  author={Sharma, Mayank and Joshi, Sandeep and Chatterjee, Tamojit and Hamid, Raffay},
  journal={Neurocomputing},
  volume={494},
  pages={116--131},
  year={2022},
  publisher={Elsevier}
}


@inproceedings{speaker_count_offline,
  title={Count and separate: Incorporating speaker counting for continuous speaker separation},
  author={Wang, Zhong-Qiu and Wang, DeLiang},
  booktitle={ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={11--15},
  year={2021},
  organization={IEEE}
}

@article{lstm,
  title={A review of recurrent neural networks: LSTM cells and network architectures},
  author={Yu, Yong and Si, Xiaosheng and Hu, Changhua and Zhang, Jianxun},
  journal={Neural computation},
  volume={31},
  number={7},
  pages={1235--1270},
  year={2019},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@article{cnn,
  title={Review of deep learning: concepts, CNN architectures, challenges, applications, future directions},
  author={Alzubaidi, Laith and Zhang, Jinglan and Humaidi, Amjad J and Al-Dujaili, Ayad and Duan, Ye and Al-Shamma, Omran and Santamar{\'\i}a, Jos{\'e} and Fadhel, Mohammed A and Al-Amidie, Muthana and Farhan, Laith},
  journal={Journal of big Data},
  volume={8},
  number={1},
  pages={53},
  year={2021},
  publisher={Springer}
}

@article{cnn_other_uses,
  title={Deep convolutional neural networks for image classification: A comprehensive review},
  author={Rawat, Waseem and Wang, Zenghui},
  journal={Neural computation},
  volume={29},
  number={9},
  pages={2352--2449},
  year={2017},
  publisher={MIT Press}
}

@article{specs_and_cnns,
  title={Audio spectrogram representations for processing with convolutional neural networks},
  author={Wyse, Lonce},
  journal={arXiv preprint arXiv:1706.09559},
  year={2017}
}

@misc{IBM_CNN,
  author       = {{IBM}},
  title        = {What are convolutional neural networks?},
  howpublished = {\url{https://www.ibm.com/think/topics/convolutional-neural-networks}},
  note         = {Accessed: 2025-08-28}
}

@article{efficient_ml,
  title={Efficient machine learning for big data: A review},
  author={Al-Jarrah, Omar Y and Yoo, Paul D and Muhaidat, Sami and Karagiannidis, George K and Taha, Kamal},
  journal={Big Data Research},
  volume={2},
  number={3},
  pages={87--93},
  year={2015},
  publisher={Elsevier}
}


@misc{resnet50_researchgate,
  title        = {Improvement of emotion recognition from facial images using deep learning and early stopping cross validation - Scientific Figure on ResearchGate},
  howpublished = {\url{https://www.researchgate.net/figure/a-Architecture-of-the-ResNet50-model-b-Residual-block-3-layer-bottleneck-block-the_fig10_359733554}},
  note         = {[Accessed 18 Aug 2025]},
  year         = {2022}
}



@inproceedings{multidecoder_dprnn,
  title={Multi-Decoder DPRNN: High Accuracy Source Counting and Separation},
  author={Zhu, Junzhe and Yeh, Raymond A. and Hasegawa-Johnson, Mark},
  booktitle={ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={3420--3424},
  year={2021},
  doi={10.1109/ICASSP39728.2021.9414205},
  url={https://arxiv.org/abs/2011.12022}
}


@misc{openAIwhisper,
  author = {Alec Radford and Jong Wook Kim and Tao Xu and Greg Brockman and Christine McLeavey},
  title = {Robust Speech Recognition via Large-Scale Weak Supervision},
  year = {2022},
  url = {https://cdn.openai.com/papers/whisper.pdf},
  note = {Accessed: 2025-08-18}
}

@inproceedings{cosine_similarity,
  title={Unsupervised speaker adaptation based on the cosine similarity for text-independent speaker verification.},
  author={Shum, Stephen and Dehak, Najim and Dehak, Reda and Glass, James R},
  booktitle={Odyssey},
  volume={6},
  pages={16},
  year={2010}
}



@inproceedings{Ng_2021, series={interspeech_2021},
   title={Pushing the Limits of Non-Autoregressive Speech Recognition},
   url={http://dx.doi.org/10.21437/Interspeech.2021-337},
   DOI={10.21437/interspeech.2021-337},
   booktitle={Interspeech 2021},
   publisher={ISCA},
   author={Ng, Edwin G. and Chiu, Chung-Cheng and Zhang, Yu and Chan, William},
   year={2021},
   month=aug, pages={3725–3729},
   collection={interspeech_2021} }


@inproceedings{Xu_2024,
  author    = {Xu, Anfeng and Huang, Kevin and Feng, Tiantian and Shen, Lue and Tager-Flusberg, Helen and Narayanan, Shrikanth},
  title     = {Exploring Speech Foundation Models for Speaker Diarization in Child-Adult Dyadic Interactions},
  booktitle = {Proceedings of Interspeech 2024},
  pages     = {5193--5197},
  year      = {2024},
  doi       = {10.21437/Interspeech.2024-717}
}



@inproceedings{Song_2021,
author = {Song, Yuanfeng and Jiang, Di and Zhao, Xuefang and Huang, Xiaoling and Xu, Qian and Wong, Raymond Chi-Wing and Yang, Qiang},
title = {SmartMeeting: Automatic Meeting Transcription and Summarization for In-Person Conversations},
year = {2021},
isbn = {9781450386517},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3474085.3478556},
doi = {10.1145/3474085.3478556},
abstract = {Meetings are a necessary part of the operations of any institution, whether they are held online or in-person. However, meeting transcription and summarization are always painful requirements since they involve tedious human effort. This drives the need for automatic meeting transcription and summarization (AMTS) systems. A successful AMTS system relies on systematic integration of multiple natural language processing (NLP) techniques, such as automatic speech recognition, speaker identification, and meeting summarization, which are traditionally developed separately and validated offline with standard datasets. In this demonstration, we provide a novel productive meeting tool named SmartMeeting, which enables users to automatically record, transcribe, summarize, and manage the information in an in-person meeting. SmartMeeting transcribes every word on the fly, enriches the transcript with speaker identification and voice separation, and extracts essential decisions and crucial insights automatically. In our demonstration, the audience can experience the great potential of the state-of-the-art NLP techniques in this real-life application.},
booktitle = {Proceedings of the 29th ACM International Conference on Multimedia},
pages = {2777–2779},
numpages = {3},
keywords = {speaker verification, meeting transcription, meeting summarization},
location = {Virtual Event, China},
series = {MM '21}
}


@article{Crocco_2016,
author = {Crocco, Marco and Cristani, Marco and Trucco, Andrea and Murino, Vittorio},
title = {Audio Surveillance: A Systematic Review},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/2871183},
doi = {10.1145/2871183},
abstract = {Despite surveillance systems becoming increasingly ubiquitous in our living environment, automated surveillance, currently based on video sensory modality and machine intelligence, lacks most of the time the robustness and reliability required in several real applications. To tackle this issue, audio sensory devices have been incorporated, both alone or in combination with video, giving birth in the past decade, to a considerable amount of research. In this article, audio-based automated surveillance methods are organized into a comprehensive survey: A general taxonomy, inspired by the more widespread video surveillance field, is proposed to systematically describe the methods covering background subtraction, event classification, object tracking, and situation analysis. For each of these tasks, all the significant works are reviewed, detailing their pros and cons and the context for which they have been proposed. Moreover, a specific section is devoted to audio features, discussing their expressiveness and their employment in the above-described tasks. Differing from other surveys on audio processing and analysis, the present one is specifically targeted to automated surveillance, highlighting the target applications of each described method and providing the reader with a systematic and schematic view useful for retrieving the most suited algorithms for each specific requirement.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {52},
numpages = {46},
keywords = {multimodal surveillance, audio surveillance, Automated surveillance}
}


@book{Helander_2014,
  title={Handbook of human-computer interaction},
  author={Helander, Martin G},
  year={2014},
  publisher={Elsevier}
}


@article{yella2014,
  title={Overlapping speech detection using long-term conversational features for speaker diarization in meeting room conversations},
  author={Yella, Sree Harsha and Bourlard, Herv{\'e}},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={22},
  number={12},
  pages={1688--1700},
  year={2014},
  publisher={IEEE}
}



@inproceedings{torchaudio,
  title={Torchaudio: Building blocks for audio and speech processing},
  author={Yang, Yao-Yuan and Hira, Moto and Ni, Zhaoheng and Astafurov, Artyom and Chen, Caroline and Puhrsch, Christian and Pollack, David and Genzel, Dmitriy and Greenberg, Donny and Yang, Edward Z and others},
  booktitle={ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={6982--6986},
  year={2022},
  organization={IEEE}
}


@article{speechprocessing_review,
url = {http://dx.doi.org/10.1561/2000000001},
year = {2007},
volume = {1},
journal = {Foundations and Trends® in Signal Processing},
title = {Introduction to Digital Speech Processing},
doi = {10.1561/2000000001},
issn = {1932-8346},
number = {1–2},
pages = {1-194},
author = {Lawrence R. Rabiner and Ronald W. Schafer}
}


@article{sciencedirect,
title = {A review of deep learning techniques for speech processing},
journal = {Information Fusion},
volume = {99},
pages = {101869},
year = {2023},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2023.101869},
url = {https://www.sciencedirect.com/science/article/pii/S1566253523001859},
author = {Ambuj Mehrish and Navonil Majumder and Rishabh Bharadwaj and Rada Mihalcea and Soujanya Poria},
keywords = {Deep learning, Speech processing, Transformers, Survey, Trends},
abstract = {The field of speech processing has undergone a transformative shift with the advent of deep learning. The use of multiple processing layers has enabled the creation of models capable of extracting intricate features from speech data. This development has paved the way for unparalleled advancements in speech recognition, text-to-speech synthesis, automatic speech recognition, and emotion recognition, propelling the performance of these tasks to unprecedented heights. The power of deep learning techniques has opened up new avenues for research and innovation in the field of speech processing, with far-reaching implications for a range of industries and applications. This review paper provides a comprehensive overview of the key deep learning models and their applications in speech-processing tasks. We begin by tracing the evolution of speech processing research, from early approaches, such as MFCC and HMM, to more recent advances in deep learning architectures, such as CNNs, RNNs, transformers, conformers, and diffusion models. We categorize the approaches and compare their strengths and weaknesses for solving speech-processing tasks. Furthermore, we extensively cover various speech-processing tasks, datasets, and benchmarks used in the literature and describe how different deep-learning networks have been utilized to tackle these tasks. Additionally, we discuss the challenges and future directions of deep learning in speech processing, including the need for more parameter-efficient, interpretable models and the potential of deep learning for multimodal speech processing. By examining the field’s evolution, comparing and contrasting different approaches, and highlighting future directions and challenges, we hope to inspire further research in this exciting and rapidly advancing field.}
}



@article{earlySpeech1,
	author = {{HATON, J.-P.}},
	title = {Problems and solutions for noisy speech recognition},
	DOI= "10.1051/jp4:1994592",
	url= "https://doi.org/10.1051/jp4:1994592",
	journal = {J. Phys. IV France},
	year = 1994,
	volume = 04,
	number = C5,
	pages = "C5-439-C5-448",
	month = "",
}


@article{SpeechEnhancement,
  author    = {Nabanita Das and Sayan Chakraborty and Jyotismita Chaki and Neelamadhab Padhy and Nilanjan Dey},
  title     = {Fundamentals, present and future perspectives of speech enhancement},
  journal   = {International Journal of Speech Technology},
  volume    = {24},
  number    = {4},
  pages     = {883--901},
  year      = {2021},
  publisher = {Springer},
  doi       = {10.1007/s10772-020-09674-2},
  url       = {https://link.springer.com/article/10.1007/s10772-020-09674-2}
}

@article{noisecancellation,
  title={Adaptive noise cancelling: Principles and applications},
  author={Widrow, Bernard and Glover, John R and McCool, John M and Kaunitz, John and Williams, Charles S and Hearn, Robert H and Zeidler, James R and Dong, JR Eugene and Goodlin, Robert C},
  journal={Proceedings of the IEEE},
  volume={63},
  number={12},
  pages={1692--1716},
  year={1975},
  publisher={IEEE}
}

@article{diarization,
  title={Speaker diarization: A review of recent research},
  author={Anguera, Xavier and Bozonnet, Simon and Evans, Nicholas and Fredouille, Corinne and Friedland, Gerald and Vinyals, Oriol},
  journal={IEEE Transactions on audio, speech, and language processing},
  volume={20},
  number={2},
  pages={356--370},
  year={2012},
  publisher={IEEE}
}


@article{speaker_counting,
  title={Speaker counting and separation from single-channel noisy mixtures},
  author={Chetupalli, Srikanth Raj and Habets, Emanu{\"e}l AP},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={31},
  pages={1681--1692},
  year={2023},
  publisher={IEEE}
}}


@article{transformers,
  title={A comprehensive survey on applications of transformers for deep learning tasks},
  author={Islam, Saidul and Elmekki, Hanae and Elsebai, Ahmed and Bentahar, Jamal and Drawel, Nagat and Rjoub, Gaith and Pedrycz, Witold},
  journal={Expert Systems with Applications},
  volume={241},
  pages={122666},
  year={2024},
  publisher={Elsevier}
}

@article{edgecomputing,
  title={Deep learning with edge computing: A review},
  author={Chen, Jiasi and Ran, Xukan},
  journal={Proceedings of the IEEE},
  volume={107},
  number={8},
  pages={1655--1674},
  year={2019},
  publisher={IEEE}
}



@book{signal_processing_book,
  title={Adaptive signal processing: applications to real-world problems},
  author={Huang, Yiteng},
  year={2003},
  publisher={Springer Science \& Business Media}
}

@misc{musan2015,
  author = {David Snyder and Guoguo Chen and Daniel Povey},
  title = {{MUSAN}: {A} {M}usic, {S}peech, and {N}oise {C}orpus},
  year = {2015},
  eprint = {1510.08484},
  note = {arXiv:1510.08484v1}
}



@INPROCEEDINGS{RoomImpulseResponseDatabase,
  author={Ko, Tom and Peddinti, Vijayaditya and Povey, Daniel and Seltzer, Michael L. and Khudanpur, Sanjeev},
  booktitle={2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={A study on data augmentation of reverberant speech for robust speech recognition}, 
  year={2017},
  url={https://www.openslr.org/28},
  pages={5220-5224},
  keywords={Speech;Training data;Acoustics;Databases;Data models;Training;Probability distribution;reverberation;augmentation;deep neural network;room impulse responses},
  doi={10.1109/ICASSP.2017.7953152}}



@inproceedings{ResNet50,
  title={Deep Residual Learning for Image Recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={770--778},
  year={2016}
}

@article{IBM_watson,
  title={The era of cognitive systems: An inside look at IBM Watson and how it works},
  author={High, Rob},
  journal={IBM Corporation, Redbooks},
  volume={1},
  pages={16},
  year={2012}
}


@article{translation,
  title={Learning to translate in real-time with neural machine translation},
  author={Gu, Jiatao and Neubig, Graham and Cho, Kyunghyun and Li, Victor OK},
  journal={arXiv preprint arXiv:1610.00388},
  year={2016}
}

@article{deep_speech_review,
  title={A review of deep learning techniques for speech processing},
  author={Mehrish, Ambuj and Majumder, Navonil and Bharadwaj, Rishabh and Mihalcea, Rada and Poria, Soujanya},
  journal={Information Fusion},
  volume={99},
  pages={101869},
  year={2023},
  publisher={Elsevier}
}

@article{efficient_models,
  title={Efficient deep learning: A survey on making deep learning models smaller, faster, and better},
  author={Menghani, Gaurav},
  journal={ACM Computing Surveys},
  volume={55},
  number={12},
  pages={1--37},
  year={2023},
  publisher={ACM New York, NY}
}


@article{multi1,
  title={Multi-modal multi-channel target speech separation},
  author={Gu, Rongzhi and Zhang, Shi-Xiong and Xu, Yong and Chen, Lianwu and Zou, Yuexian and Yu, Dong},
  journal={IEEE Journal of Selected Topics in Signal Processing},
  volume={14},
  number={3},
  pages={530--541},
  year={2020},
  publisher={IEEE}
}
@article{multi2,
  title={Multichannel signal processing with deep neural networks for automatic speech recognition},
  author={Sainath, Tara N and Weiss, Ron J and Wilson, Kevin W and Li, Bo and Narayanan, Arun and Variani, Ehsan and Bacchiani, Michiel and Shafran, Izhak and Senior, Andrew and Chin, Kean and others},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={25},
  number={5},
  pages={965--979},
  year={2017},
  publisher={IEEE}
}


@misc{massivemodel,
  author       = {Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
  title        = {Robust Speech Recognition via Large-Scale Weak Supervision},
  year         = {2022},
  publisher    = {arXiv},
  doi          = {10.48550/arXiv.2212.04356},
  url          = {https://arxiv.org/abs/2212.04356}
}


@book{asr,
  title={Automatic speech recognition},
  author={Yu, Dong and Deng, Lin},
  volume={1},
  year={2016},
  publisher={Springer}
}




@misc{bat_echolocation_jones,
  author       = {Gareth Jones},
  title        = {Echolocation Calls of British Bats},
  year         = 2019,
  url          = {https://www.garethjoneslab.com/british-bat-echolocation},
  note         = {Accessed: 2025-08-16},
  howpublished = {\url{https://www.garethjoneslab.com/british-bat-echolocation}}
}


@inproceedings{libricss,
  title={{Continuous Speech Separation: Dataset and Analysis}},
  author={Chen, Zhuo and Yoshioka, Takuya and Lu, Liang and Zhou, Tianyan and Meng, Zhong and Luo, Yi and Wu, Jian and Xiao, Xiong and Li, Jinyu},
  booktitle={ICASSP 2020--2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  year={2020},
  organization={IEEE},
  note={arXiv:2001.11482}
}


@inproceedings{librispeech,
  title={{LibriSpeech: An ASR corpus based on public domain audio books}},
  author={Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={5206--5210},
  year={2015},
  organization={IEEE}
}

@inproceedings{ami,
  title={{The AMI meeting corpus: A pre-announcement}},
  author={Carletta, Jean and Ashby, Simone and Bourban, Sebastien and Flynn, Mike and Guillemot, Mael and Hain, Thomas and Kadlec, Jaroslav and Karaiskos, Vasilis and Kraaij, Wessel and Kronenthal, Melissa and others},
  booktitle={International Workshop on Machine Learning for Multimodal Interaction},
  pages={28--39},
  year={2005},
  organization={Springer}
}

@inproceedings{chime,
  title={{The CHiME speech separation and recognition challenge}},
  author={Barker, Jon and Marxer, Ricard and Vincent, Emmanuel and Watanabe, Shinji},
  booktitle={2015 IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU)},
  pages={504--511},
  year={2015},
  organization={IEEE}
}

@inproceedings{librimix,
  title={{Wham!: Extending speech separation to noisy environments}},
  author={Wichern, Gordon and Antognini, Joseph and Flynn, Michael and McQuinn, Lydia and Crow, Dave and Manilow, Ethan and Le Roux, Jonathan},
  booktitle={Interspeech 2019},
  pages={1368--1372},
  year={2019},
  organization={ISCA}
}

@inproceedings{voxceleb,
  title={{VoxCeleb: a large-scale speaker identification dataset}},
  author={Nagrani, Arsha and Chung, Joon Son and Zisserman, Andrew},
  booktitle={Interspeech 2017},
  pages={2616--2620},
  year={2017},
  organization={ISCA}
}

@inproceedings{voxceleb2,
  title={{VoxCeleb2: Deep speaker recognition}},
  author={Chung, Joon Son and Nagrani, Arsha and Zisserman, Andrew},
  booktitle={Interspeech 2018},
  pages={1086--1090},
  year={2018},
  organization={ISCA}
}




@article{adam,
  title={Adam: A Method for Stochastic Optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@online{speech_and_harmonics,
  author       = {Arnold, Godfrey Edward},
  title        = {Speech},
  year         = {2024},
  url          = {https://www.britannica.com/topic/speech-language},
  note         = {Accessed: 2025-08-17},
  organization = {Encyclopedia Britannica},
  month        = dec
}


@inproceedings{optuna_2019,
    title={Optuna: A Next-generation Hyperparameter Optimization Framework},
    author={Akiba, Takuya and Sano, Shotaro and Yanase, Toshihiko and Ohta, Takeru and Koyama, Masanori},
    booktitle={Proceedings of the 25th {ACM} {SIGKDD} International Conference on Knowledge Discovery and Data Mining},
    year={2019}
}


@misc{streamlit,
  title        = {{Streamlit}: A Faster Way to Build and Share Data Apps},
  author       = {{Streamlit}},
  howpublished = {\url{https://streamlit.io/}},
  note         = {Accessed: 2025-08-18}
}


@article{modelsizes,
author = {Zheng, YuYu and Huang, HaoXuan and Chen, Junming},
year = {2024},
month = {02},
pages = {012015},
title = {Comparative analysis of various models for image classification on Cifar-100 dataset},
volume = {2711},
journal = {Journal of Physics: Conference Series},
doi = {10.1088/1742-6596/2711/1/012015}
}

@misc{sounddevice,
  author       = {Michael Brandl},
  title        = {sounddevice: Play and record sound with Python},
  year         = {2021},
  howpublished = {\url{https://python-sounddevice.readthedocs.io/}},
  note         = {Accessed: 2025-08-26}
}