
\begin{abstract}
Voice activity detection (VAD) and speaker counting are critical upstream components of speech processing pipelines, enabling downstream tasks such as speaker identification and transcription to operate effectively. Conventional state-of-the-art approaches rely on transformers or recurrent architectures and multi-channel audio, which are unsuitable for real-time deployment on resource-constrained devices due to slow inference and unrealistic training data.\newline

\noindent This paper investigates the use of convolutional neural networks (CNNs) as lightweight speech processing solutions via single-channel spectrogram inputs. Each model was trained on a combined dataset incorporating LibriCSS speech and noise samples from various sources. The models were evaluated in real-time using Streamlit, a python app development framework.\newline

\noindent Results demonstrate that compact CNN-based models easily solve VAD, reaching 99.5\% accuracy in validation and generalising in real-time with low latency. For speaker counting, performance reached 65\% accuracy on validation data, indicating that CNNs are viable but larger or hybrid architectures may be necessary as task complexity increases. These findings highlight that CNN-based models are effective for speech processing classification tasks. As a result, overly complex models and datasets may become redundant as industry drives for models that thrive in production, not in development. This highlights the importance of aligning model and dataset design with task requirements, and addresses a key gap in existing research. Models and datasets are often theoretically `perfect', yet fail when deployed in the real world.
\end{abstract}
